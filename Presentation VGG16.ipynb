{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, InputLayer, Dense, Flatten, Conv2D,Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import  Model\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "import random\n",
    "import PIL\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of training and testing images : (240, 240)\n",
      "Number of training set images :  721\n",
      "Number of testing set images :  241\n"
     ]
    }
   ],
   "source": [
    "data_path='D:/Work/Jadavpur_university/Research/train_set'\n",
    "list_folder=os.listdir(path = data_path)\n",
    "data=[]\n",
    "im_size=240    \n",
    "for i in list_folder:\n",
    "    new_path=os.path.join(data_path,i) \n",
    "    pic_list=os.listdir(new_path)                                               \n",
    "    for img in pic_list:\n",
    "        pic=os.path.join(new_path,img)   \n",
    "        arr=cv2.imread(pic)    \n",
    "        data.append([arr,list_folder.index(i)])    \n",
    "        \n",
    "random.shuffle(data)  \n",
    "x_train,y_train=[],[]\n",
    "for i,j in data:\n",
    "    x_train.append(i)\n",
    "    y_train.append(j)\n",
    "x_train=np.array(x_train).reshape(-1,im_size,im_size,3)\n",
    "y_train=np.array(y_train).reshape(-1,1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "X_train = x_train/255\n",
    "y_train = y_train.toarray()\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train,y_train, test_size=0.25)\n",
    "\n",
    "\n",
    "print('Dimension of training and testing images :', X_train.shape[1:3])\n",
    "print('Number of training set images : ', X_train.shape[0])\n",
    "print('Number of testing set images : ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last layer shape: (None, 15, 15, 512)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(input_shape = (240,240,3),\n",
    "              include_top = False,\n",
    "              weights = None)\n",
    "\n",
    "weights = 'D:/Work/Jadavpur_University/Research/weights/vgg16.h5'\n",
    "model.load_weights(weights)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "last_layer = model.get_layer('block5_conv3')\n",
    "last = last_layer.output\n",
    "\n",
    "print('Last layer shape:', last.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 240, 240, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 240, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 120, 120, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 120, 120, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 60, 60, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 400)       205200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 400)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               5017856   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 19,971,156\n",
      "Trainable params: 5,256,468\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Conv2D(400, (1,1), activation = 'relu', input_shape = last.shape[1:])(last)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = Dropout(rate = 0.25)(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(rate = 0.25)(x)\n",
    "x = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "classifier = Model(inputs = model.input, outputs = x)\n",
    "opt1 = Adam(learning_rate = 0.002)\n",
    "opt2 = RMSprop(learning_rate = 0.001)\n",
    "classifier.compile(optimizer = opt1 , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 241 samples\n",
      "Epoch 1/20\n",
      "721/721 [==============================] - 34s 48ms/sample - loss: 1.6983 - accuracy: 0.6325 - val_loss: 0.5147 - val_accuracy: 0.7759\n",
      "Epoch 2/20\n",
      "721/721 [==============================] - 33s 46ms/sample - loss: 0.3960 - accuracy: 0.8571 - val_loss: 0.2777 - val_accuracy: 0.9046\n",
      "Epoch 3/20\n",
      "721/721 [==============================] - 33s 46ms/sample - loss: 0.2298 - accuracy: 0.9223 - val_loss: 0.1963 - val_accuracy: 0.9212\n",
      "Epoch 4/20\n",
      "721/721 [==============================] - 33s 46ms/sample - loss: 0.1640 - accuracy: 0.9320 - val_loss: 0.1609 - val_accuracy: 0.9461\n",
      "Epoch 5/20\n",
      "721/721 [==============================] - 33s 46ms/sample - loss: 0.0975 - accuracy: 0.9626 - val_loss: 0.2043 - val_accuracy: 0.9461\n",
      "Epoch 6/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.1151 - accuracy: 0.9612 - val_loss: 0.2559 - val_accuracy: 0.9253\n",
      "Epoch 7/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.1642 - val_accuracy: 0.9378\n",
      "Epoch 8/20\n",
      "721/721 [==============================] - 35s 48ms/sample - loss: 0.0708 - accuracy: 0.9778 - val_loss: 0.1509 - val_accuracy: 0.9461\n",
      "Epoch 9/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0314 - accuracy: 0.9958 - val_loss: 0.1206 - val_accuracy: 0.9627\n",
      "Epoch 10/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0267 - accuracy: 0.9931 - val_loss: 0.1107 - val_accuracy: 0.9710\n",
      "Epoch 11/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0484 - accuracy: 0.9875 - val_loss: 0.4094 - val_accuracy: 0.9004\n",
      "Epoch 12/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.1951 - val_accuracy: 0.9502\n",
      "Epoch 13/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0773 - accuracy: 0.9778 - val_loss: 0.6006 - val_accuracy: 0.8797\n",
      "Epoch 14/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0856 - accuracy: 0.9764 - val_loss: 0.2082 - val_accuracy: 0.9627\n",
      "Epoch 15/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0502 - accuracy: 0.9889 - val_loss: 0.1770 - val_accuracy: 0.9544\n",
      "Epoch 16/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0067 - accuracy: 0.9972 - val_loss: 0.1732 - val_accuracy: 0.9627\n",
      "Epoch 17/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.2552 - val_accuracy: 0.9544\n",
      "Epoch 18/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 0.0021 - accuracy: 0.9986 - val_loss: 0.1554 - val_accuracy: 0.9668\n",
      "Epoch 19/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 4.0765e-04 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9710\n",
      "Epoch 20/20\n",
      "721/721 [==============================] - 34s 47ms/sample - loss: 8.4229e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, Y_train, batch_size = 10, epochs = 20, shuffle = True, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfr48c9DQgmEaui9KYJ0iAUVFBXEgoIKfNe17CqioKKrq+uqv6jrisKujbaowCoI6CpWJEgRIYomSC9CCCEJQTqhhpR5fn/cSQzJJJmEKSF53q/XvDJz7zn3PjMM95l7zrnniqpijDHG5Fcp2AEYY4wpmyxBGGOM8cgShDHGGI8sQRhjjPHIEoQxxhiPQoMdgC9FRERoq1atgh2GMcacM1avXn1AVet7WleuEkSrVq2Ii4sLdhjGGHPOEJFdha2zJiZjjDEeWYIwxhjjkSUIY4wxHlmCMMYY45ElCGOMMR75LUGIyHQR2SciGwtZLyLylojEi8h6EemRZ91AEfnVve5pf8VojDGmcP48g5gJDCxi/fVAe/djJDAFQERCgEnu9R2BESLS0Y9xGmOM8cBv10Go6vci0qqIIoOB99WZb3yViNQRkcZAKyBeVRMARGSuu+xmf8VqjDE+l5UFJ07A8ePFP06fPrt9hYfDX//qm7jzCOaFck2B5DyvU9zLPC2/uLCNiMhInDMQWrRo4fsojTFlmypkZ5/dNjIyij+Yl3R9enrJYhApffwNG5a7BOHp09AilnukqtOAaQC9evWyux+ZkktKgt27oVEj5z9a9erBjsgU58gRWLwYoqOdR3Jy8XV8pUYN5xd73kft2tCsmed1xT1q1IAqVQIXfwkEM0GkAM3zvG4GpAJVCllujG+dOAEvvwwTJkBm5u/La9VyEkWjRgUfeZc3aACVKwcv/ookOxtWr3aSwcKF8NNPzrJateCaa+C++6DSWXSphoZCzZqeD955X1evfnb7OccEM0F8AYxx9zFcDKSp6h4R2Q+0F5HWwG5gOPB/QYzTlDeq8Pnn8OijztnD3XfDHXfAvn3w229nPtavh0WLIC3N87YiIpxk0bo1dOv2+6NVq8AdSHJuG3w2TRRl0Z49zmcfHe38PXjQeY89e8Lf/gYDBsDFF1uS9iO/JQgRmQP0AyJEJAX4f0BlAFWdCiwABgHxwEngXve6LBEZA0QDIcB0Vd3krzhNBbNjBzzyCCxYAJ07w/ffwxVXFF/v1CnYu9d55E8ie/bAtm3w9dfgcjnla9aErl1/Txhdu8JFF0G1aqWLOyvLSWbx8c57iI///ZGQAE2awF/+AvfeC2FhpdtHsGVkQEzM72cJ69Y5yxs2hBtucBLCtddCfY8Tjxo/ENXy02zfq1cvtdlcjUfp6fDqq/DKK84vzhdfhDFjfPvr8+RJ2LQJ1q51HuvWOY/jx531ISHQocPvCSMneeQc8E6fhsTEMw/+Oclg504nSeQIC4O2baFdO2jTBn74AVatcrb16KPw0ENQt67v3pu/pKfDRx/B//4Hy5Y5n1VoKPTpAwMHOkmha9cK1awTaCKyWlV7eVxnCcKUe998Aw8/7Bxshw2Df/0LmjYNzL5dLucX/rp1ZyaOvJ2qTZo4nZRJSb+fgYBzFtK+/e+JIO+jceMzm5RUYcUKGDfOeb/h4TByJDz2mNN5WtYkJsKUKfDee07TUcuWMGiQkxCuusrpWzABYQnCVExJSTB2LMyfDxdcAJMmQf/+wY7KcfDg72cYa9c6Ha45B/+chBARUbp+hfXr4bXXYO5c55f3H/7gDIG88ELfv4+ScLng22+df4evvnLe2+DBzpncVVeVvz6Uc4QlCFOxZGTAv/8NL73kvH7uOXj88TI7lNBvEhOds6X33nP6UAYPhqeegksvDWwcR47AzJkweTJs3+40g40cCQ88AM2bF1vd+FdRCcIa9kz5snSp02adM8plyxZ4+umKlxzAGUn19tuwaxc8/7zTBHXZZXDllU4nvb9/HK5f7ySBpk2dpq6ICJg1y2le+8c/LDmcAyxBmPIhNRVGjHCakDIznQPgp5+CXV3v/GJ/4QUnUbzxhnNmccMNTiKdNevMa0DOVkaG07R1xRXO9t9/H4YPd65h+OEHp7mralXf7c/4lTUxmXOHKhw+fOYQ0717nQPf9OnOwelvf3OaUUo7nLQiyMyEOXOcfopNm5wkeuutztXAxV0olvMICzuzz2D3bpg2zXn89pszsuqhh5xht/XqBe+9mmJZH4Qp206fdpod8h/4819vsHev51+7Vao4zUmvv+508BrvuFzOmdb48c4v/BMnvK8rcmYS2bnT2d7118Po0c4QVRuaGhAnMk6w98Re2tRtU6r6liBM2XTggNNGPnEiHDp05rpKlZypLIqa6iLnUbu2jYDxBZfL6cwuzWR1zZs7Hc+WoP3iSPoRdhzaQfyheOIPxbPj8O/P9xzfQ5OaTdj9+O5SbbuoBBHMqTZMReVpdM2ttzpj+3OSQESEc2GZCZxKlZyzgRo1nH8DEzCqyv6T+52Df04iOPz784OnDp5RvnF4Y9rWa8uAdgNoV7cd7eq1Q1URH/9QsgRhAmf9eudq5nnznIPRnXfCk08Gf3x+KWS5svgp5ScWxi9k8c7FXNvmWl686sVgh2XKMJe6SD2WWiAJ5Lw+lnEst6wgtKjdgnb12jH0wqG0q+ckgbb12tKmbhvCq4QHJGZrYjL+perMd/Tqq79f4fvAA84FbGXxCt8iJKUlER0fzcIdC1mSsIS002lUkkrUr16fI+lHSH4smfo1bJ6giizLlUVSWtLvTUGHduQmgYTDCaRn/X6PiNBKobSu09o58Ndtm5sE2tVrR6s6ragaGpjRXtbEZALP5XJmTH31VWdq5vr1nbHv58ocQcCpzFMs37U8NylsPbAVgGa1mnFbx9sY0HYA17S5hj3H99BpcifeW/MeT19ut1CvSA6ePMj0NdNZmriU+EPxJB5JJMv1+5xZYaFhtK3XlvPPO5/r213/+5lA3bY0r92c0Epl+xBsZxDGt06fhtmznSGUv/7qTIP9xBPnxCyjqsqWA1tYGL+Q6B3RLE9czuns01QNqUrfVn0Z0HYAA9sN5MKICwu09fZ/v7/zi/GRHWX+P705e7G7Y5kUO4m5G+dyOvs0XRt25YKIC3L7A9rWc84IGoc39nm/gK/ZGYQp2po1znTVRY17Dy3mq3L0qDMG/vXXnYvWunVzxtrfdlvxdYNIVVmcsJh5m+YRvSOalKMpAHSI6MCDvR5kQLsBXNnySqpXLvouc2N6j2HIR0P4attX3NLhlkCEXmZs2b+FXw/+Sr9W/ahTrU5A930i4wTLdy3nVOYprmp9FfXC/HfNRXpWOvM2zmNS7CRiU2MJrxLOn7v/mYd6P0SnBp38tt9gKrv/c01gzJ8Pt99e/D19q1Yt/JaJVas6c/inpcHVV8OMGc68/WX8l9O639bxxLdPsDhhMbWr1qZ/m/48f+XzDGg3gBa1S3YF9k0X3ETzWs2Z+PPECpcghv1vGBv2bSBEQri42cUMbDuQAe0G0LNxT0Iq+XYkmqqyYd8GouOjid4RzYqkFWRkZwBQSSoR2TSSAW0HMKDtACKbRvpk/zsP72Rq3FTeW/MeB08d5MKIC5l4/UT+2PWP1KpavmedtSamiuyrr2DIEOcOXf/5j9M8VNRN2YsaF9+9uzNjaO/ewX5XxUo9lsqzS59l5tqZ1KlWh+f7Ps9DvR+iSsjZzdf0yopXeGbpM2x+aDMX1j/3RmaVxvq96+k6tStjLx5LeJVwFu5YyOrU1ShKvbB6XNf2Oga0HcB1ba+jSc0mpdrHwZMH+TbhW6J3RLNoxyJSjzl3IL6owUW5zX7VK1dn0Y5FRO+I5ufdP+NSF3Wr1eWaNtc4CaPdAJrV8n5QhEtdLNqxiEmxk/h629dUkkrc0uEWRvceTb9W/cp8s1FJ2IVypqDoaLj5ZujSxZmCuU5gmwaC4XjGcSb8MIHxP4wnMzuThyMf5tkrn6VumG86zfef2E+z15txf4/7mThook+2WdY99e1T/HvVv0l9PDV3BNf+E/tzD+jR8dHsPbEXgM4NOjOw3UAGtB3A5S0uL3SUTs4Q4ugdzllC7O5YFKVutbpc2/ba3IRT2AH/0KlDLE5YnNuXlJNQOtXvlJtQrmh5BdVCC07HcvjUYWasncGUuCnEH4qnYY2GjOw5kpE9R5YowZxLLEGYMy1ZAjfe6NzdbMmScj9XTrYrm5lrZ/LcsufYc3wPt3e8nXHXjCv11ARFufuzu/l0y6fsfnx3uW9+cKmLFq+3oHvj7nw54kuPZVSV9XvX5x6sVyatJNOVSfXK1enXql9uc1S10Gq5zUaLExbnDiG+uOnFuWcAvZv0LnGTkaqyaf+m3P1/v+t7MrIzCAsNo2+rvrn7P5V5ikmxk/hww4ecyjrF5S0uZ3Tv0Qy5cMhZn1mWdUFLECIyEHgT597S76rquHzr6wLTgbZAOvAnVd3oXpcIHAOygazC3kBeliC8sHy5M19O27bOLR4jIoIdkV99u+Nbnvj2CdbvXc8lzS7hX9f9i8uaX+a3/cWlxtH7nd68NfAtHr74Yb/tpyxYtnMZV79/NXOHzmXYRcO8qnM84zjLdi4jekc0C+MXsuPwjjPWN63ZNPdXfv82/X3e6ZzTqZ0zdHnbwW2566pXrs6dne/kod4P0bVRV5/utywLSoIQkRBgG3AtkALEAiNUdXOeMuOB46r6goh0ACapan/3ukSgl6oe8HafliCKERPjTGrXogV8950z11E5tXHfRp789kkWxi+kdZ3WjLtmHLd3vD0gbceXvHsJh9MPs2X0FipJ+Z2w7s+f/5mPN3/Mb0/8Vuwor8LsOLSD6B3RnM46zXVtr6Nj/Y4Bbd9PPJJIdHw0LnUxovOIgI/CKguCNcw1EohX1QR3EHOBwcDmPGU6Aq8AqOpWEWklIg1Vda8f46qYfv7ZOXNo0sRpViqnyeG347/x/LLneW/Ne9SsUpMJ105gTOSYgF2VCjAmcgx/nP9HliQs4dq21/p9f5NjJ1NJKjGq1yi/7yvHqcxT/G/L/xjacWipkwNA23pteajeQz6MrGRa1WnFA70eCNr+yzp//rxpCuS5Mzsp7mV5rQOGAIhIJNASyOkJUmCRiKwWkZGF7URERopInIjE7d+/32fBlyu//ALXXedczbx0qTMpXjlzMvMk//j+H7R/uz0z1s7g4ciH2fHIDv5y2V8CmhwAbu94O/Wr12dirP87qjfs3cAj3zzCXxb9hcOnDvt9fzm+2vYVR08f5c7OdwZsnybw/HkG4ek8MX971jjgTRFZC2wA1gA516n3UdVUEWkAfCsiW1X1+wIbVJ0GTAOnicln0Z8jVJWPN3/Mlv1bPBfY+xvM/C/0qwL33gzx70F8wWID2w3k4mYX+zdYP0g4nMDX277m1ZhX2X1sN7d2uJVXr3mV9ue1D1pMVUOrMrLnSP654p8kHkmkVZ1WftmPqjJ6wWjCKodxPOM4M9fO5LFLH/PLvvKbtWEWTWo2oV+rfgHZnwkOfyaIFCDvTWebAal5C6jqUeBeAHEaHne6H6hqqvvvPhGZj9NkVSBBVGSZ2ZmMWTCGab9MK7rgJQCnYO0bhRZ58fsXearPU0T1iyrTozZOZJzgu8TvckelbD+0HYDeTXrz4dAPubLllUGO0PFAzwcYt3IcU2Kn8Oq1r/plHx9u+JAVSSuYduM0/rvuv0yKncSjlzzq936PAycPsGD7Ah69+FGfXwhnyhhV9csDJ/kkAK2BKjjNSZ3ylakDVHE/vx943/28BlAzz/MfgIHF7bNnz55aURw8eVCvmnmVEoU+s/gZzcrOUpfL9ftj82Z1NWygrsaN1PXrr2euy/c4mn5U7/v8PiUK7T61u27atynYby+Xy+XSdb+t09dWvqZX//dqrfJSFSUKDftHmA6aPUjfXPWmbt2/VV0uV7BDLWDovKFa79V6ejLjpM+3nZaepo0mNNLe03prtitb52yYo0ShC7Yt8Pm+8pv882QlCl2zZ43f92X8D4jTwo7jha3wxQMYhDOSaQfwd/eyUcAo9/NLge3AVuBToK57eRt3QlkHbMqpW9yjoiSIrfu3aru32mmVl6roB+s+KFhg2zbVxo1VGzRQ3bLF6+1+tuUzrf9afa36UlV948c3NNuV7cOovXfgxAGds2GO3vPZPdp4QmMlCiUKvWjyRfpE9BP67Y5v9VTmqaDEVhLLdi5TotDpv0z3+bYfW/iYSpTozyk/q6rq6azT2mhCIx00e5DP95Vfn/f6aKdJncpkUjYlF7QEEehHRUgQi+IXae1XamuD8Q30h6QfChZISFBt1kw1IkJ1w4YSb/+3Y7/pjR/eqESh17x/jSanJfsg6qJlZmdqTFKMPrf0OY18J1IlSpQotO64unrHx3fo9F+ma0pait/j8DWXy6WdJnXS7lO7+/RgumHvBg15IURHfjHyjOX/b9n/U4kS3X5wu8/2ld+OQzuUKPSVFa/4bR8msCxBlBMTf5qoIS+EaOfJnTXxcGLBArt2qbZsqVq3rurataXej8vl0mlx07TGyzW0zrg6OmfDnNIHXYTktGR9bulz2nB8QyUKrfRCJb303Us1almU/pj8o2ZlZ/llv4E0JXaKEoXnZF4KLpdL+87oq/VeracHThw4Y93uo7s19MVQfXzh4z7ZlycvLX9JiUJ3Hdnlt32YwLIEcY7LzM7Uh756SIlCb55zsx5NP1qwUEqKatu2qrVrq8bF+WS/2w9u10vevUSJQkf8b4QeOnnorLfpcrl0ScISHTJviIa8EKISJXrD7Bt03sZ5Ptl+WXPs9DGt/UptHfG/ET7Z3ofrP1Si0KmxUz2uH/bxMK0zro4eP33cJ/vLy+Vy6QVvX6B9Z/T1+bZN8FiCOIcdOnlIr3n/GiUK/euiv3r+Vb1nj+r556vWrKm6apVP95+Znan/WP4PDX0xVJv9u5ku3rG4VNtJS0/Tt396Wy+ceKEShdZ7tZ4+uehJTTiU4NN4y6Kx34zV0BdDNfVo6llt52j6UW3yryba8z89Cz27WrFrhRKFToubdlb78iR2d6wShb6z+h2fb9sEjyWIc9S2A9v0/LfP18ovVtYZa2acuTI7W3XFCtWxY1UbNVKtUcN57Sexu2P1grcvUKLQsd+M9Xpkzsa9G/XBrx7U8H+GK1For2m9dMaaGX4Z2VNWbTuwTYlCX/juhbPazhPRTyhR6Krkwn8EuFwu7Tqlq3aZ0sXnnciPfvOoVnmpih4+ddin2zXBZQniHLQkYYnWHVdXI16L0BW73Af+zEzVpUtVH3rIGaUEqlWqqN50k+qPP/o9phMZJ/ThBQ8rUWjHSR31l9RfPJbLyMrQjzZ+pH1n9FWi0KovVdW75t+lP6X85PcYy6qBswZq4wmNNSMro1T1N+3bpKEvhuqfP/9zsWXfWf2OEoUuT1xeqn15kpmdqQ3GN9Ah84b4bJumbLAEcY6ZGjtVQ18M1U6TOmnCvl9VFy5Uvf9+Z2QSqIaFqQ4Zovrhh6ppaQGPb+H2hdp4QmOt/GJlfWXFK7nNHalHUzVqWZQ2+VcTJQpt+XpLHbdinO4/sT/gMZY1X/36lRKFzts4r8R1XS6XXv3fq7XOuDq67/i+YsufyDihdcfV1ds/ur00oXr0zfZvlCj0082f+mybpmwoKkHYLUfLkCxXFn+J/gtv/fwWg2r1Yk5se2o9ewkcPuzc2vPGG2HoUGfSvRo1ghbngHYD2PDgBh78+kH+tuRvfL39a5rUbMKnWz4ly5XFgLYDmHrDVAa1H2RX2roNbDeQNnXbMPHnidzR6Y4S1f1488cs3bmUSYMm5d6UpyjVK1fnz93/zOurXmf30d00rZV/CrSSm7V+FnWq1WFQ+0FnvS1zDiksc5yLj3P5DOLIoVQdMKGbEoU+fmNlzRKcEUl33aX6+eeqp8rehWEul0s/WPeB1nqlltYZV0cfW/iYbjuwLdhhlVkTYiYoUejaPd4PQT52+pg2/VdT7T61e4mG/e44tEMlSvS5pc+VJtQCMVR/uXqB6y5M+YCdQZRtO574MzednsH2uso739XgvvOHw4Lb4OqroUrZnRdJRLizy53c1vE2AI+3cDS/u7f7vTy37DkmxU5i2k3FzJ/l9tLyl9h9bDcf3/5xic7G2tRtww3n38B/Vv+Hv1/x97Oa0fbzrZ9zMvMkd3axmVsrmvJ7N5NzwKnMU/zzw1F0rzKdvXUq823XCdy39Ai8+y4MHFimk0Ne1UKrWXLwQr2wevyh8x+YtX6WV1Nzbz2wlX+v+jf3druXS5tfWuL9jek9hn0n9vHJlk9KE26uWRtm0bJ2S/q06HNW2zHnHksQQeBSFx+s+4ALJl7A37f/h6tTKhM3ajX9hv4FQu2krjwbHTmaU1mnmL5mepHlVJWHv3mY8CrhjLtmXJFlC3Nt22tpX689E38u/X0p9h7fy6Idi/hD5z+U67vjGc/sXzzAlicuJ/KdSO767C4ahNbmu5nwWfMnad30omCHZgKgW6NuXN7icibHTSbblV1ouU+2fMLihMW8dNVLNKhRurv/VZJKjO49mh9TfmR16upSbWPuxrm41MUfuvyhVPXNuc0SRID8euBXBs8dTL//9mPfiX18cOsH/Ly5D31Tq8DD5fvm9uZMD0c+TMLhBBbGL/S4/kTGCR6PfpyuDbue9W1E7+52NzUq12BS7KRS1Z+1YRbdG3WnY/2OZxWHOTdZgvCz/Sf2M2bBGDpN7sSyncv459X/5Ncxv3Jno+uoNPO/cNdd0KhRsMM0AXRrh1tpHN640FuSvrziZZKPJjNp0CRCK51dk2OdanX4Y5c/8uGGDzl48mCJ6m49sJW41DjrnK7ALEH4SXpWOq+ufJV2b7djatxURvYcSfwj8fztir8RVjkMJk2C9HT4y1+CHaoJsMohlRnVaxQL4xey/eD2M9ZtO7iNCT9M4K6ud/msU3h05GhOZ5/mvTXvlaje7PWzqSSVGH7RcJ/EYc49liB8zKUu5myYQ4eJHXh6ydNc2fJKNjy4gck3TP69LfnkSSdB3HwzdOgQ3IBNUIzsOZLKlSozOXZy7jJV5ZFvHiGschivXfOaz/Z1UYOL6NeqH5Nji+73yEtVmb1hNv1b96dJzSY+i8WcWyxB+NDKpJVc8u4l/N+n/0fdsLos/uNivhzxJRfWv/DMgjNmwMGD8OSTwQnUBF2j8Ebc1vE2ZqydwfGM4wB8tvUzondE82K/F2kY3tCn+xvTewy70nbx9favvSr/Y8qP7Dyy05qXKjhLED4QfyieoR8N5YoZV5B6LJWZg2eyeuRq+rfpX7Bwdjb8+99wySXQx8aVV2RjIseQdjqN2etnczLzJGOjx9K5QWdGR472+b4GdxhMs1rNePvnt70qP2v9LMJCw7i1w60+j8WcO/yaIERkoIj8KiLxIvK0h/V1RWS+iKwXkZ9F5CJv65YVLnXRd2ZfouOjeemql9j28Dbu7nZ34WPGP/0UEhLgiSdAJLDBmjLl0maX0r1RdybGTuSfK/5JUlqSTzqmPQmtFMqDvR5kccJituzfUmTZjOwM5m2ax+AOg6lZtabPYzHnDr8lCBEJASYB1wMdgREikn+s3DPAWlXtAtwFvFmCumXCpn2bSD2WyqRBk3j2ymepXrl64YVVYfx4aNcObrklcEGaMklEGBM5ho37NvLPFf/kzi53ckXLK/y2v/t63EeVkCpn9Ht4sjB+IYdOHeLOzta8VNH58wwiEohX1QRVzQDmAoPzlekILAFQ1a1AKxFp6GXdMiEmOQaAy1tcXnzh77+H2Fh4/HEIsVlODYy4aAT1wuoRXiXcpx3TnjSo0YBhnYYxc91Mjp4+Wmi5WetnEVE9guvaXufXeEzZ588E0RRIzvM6xb0sr3XAEAARiQRaAs28rIu73kgRiRORuP379/sodO/FJMfQKLwRbeq2Kb7w+PEQEQH33OP3uMy5IaxyGHOGzuHTYZ/SuGZjv+9vTOQYjmcc54N1H3hcn5aexhe/fsHwTsOpHFLZ7/GYss2fCcJTA7vmez0OqCsia4GHgTVAlpd1nYWq01S1l6r2ql+/+LnyfW1l0kr6NO+DFNefsHkzfP01jBkDYWGBCc6cE65rex3XtLkmIPuKbBpJ7ya9mRg70bljWD6fbPmE09mnbfSSAfybIFKA5nleNwNS8xZQ1aOqeq+qdsPpg6gP7PSmblmQeiyVxCOJ9GnuxWikCROcxDDa9yNUjCmJMZFj2HpgK0t3Li2wbtb6WbSr147IppFBiMyUNf5MELFAexFpLSJVgOHAF3kLiEgd9zqA+4DvVfWoN3XLgpgkp/+h2CteU1Nh1iy4916nicmYILqj0x1EVI8oMNVHytEUvkv8jjs731n8GbGpEPyWIFQ1CxgDRANbgI9UdZOIjBKRnBnILgQ2ichWnBFLjxZV11+xltbKpJWEhYbRvVH3ogu+9ZZz/cPjjwcmMGOKUC20Gvf3uJ8vfv2CXUd25S6fs2EOitrMrSaXeGqHPFf16tVL4+LiAre/ab2oWbUmy+5eVnihY8egeXO49lr4+OOAxWZMUZLSkmj9Zmv+etlfeeWaVwDoOrUrYaFhrLpvVZCjM4EkIqtVtZendXYldSkdzzjO2t/WFt//8M47kJZm02qYMqVF7Rbc0uEW3vnlHdKz0lm/dz3r9663zmlzBksQpfTz7p/J1uyir3/IzIQ33oArr4RI6/QzZcuY3mM4eOog8zbOY/b62YRICMM6DQt2WKYMsftbltLKpJUIwqXNirhX8Lx5kJwMk4u+ctWYYOjXqh8d63fkrZ/fYt+JfQxsN5D6NQI/VNyUXXYGUUoxyTFc1OAialer7blAzrQaF14IgwYFNjhjvCAijOk9hl/2/ELK0RRrXjIFWIIohWxXNj8m/1h0/8O338L69c6kfJXsYzZl0x+7/pFaVWsRXiWcmy+4OdjhmDLGmphKYcO+DRzLOFZ0/8P48dC4MfzBhgyasiu8SjhvDXyLjOyMoieaNBWSJYhSKPYCuTVrYPFieOUVqFo1gJEZU3J3d7s72CGYMsraPkohJjmGJjWb0LJ2S88FJpB0Q/YAACAASURBVEyA8HAYNcrzemOMOQdYgiiFmOSYwifo27XLGb10//1Qp07ggzPGGB+xBFFCyWnJJKUlFd7/8MYbzt+xYwMXlDHG+IEliBLKuUGQxxFMhw87V04PHw4tWgQ4MmOM8S1LECUUkxRDjco16Nqoa8GV//kPnDjhDG01xphznCWIEopJjuGSZpcUvLH86dPw5ptwzTXQrVtwgjPGGB+yBFECx04fY93edZ6bl2bPht9+s0n5jDHlhiWIEliVsgqXugpe/+ByOUNbu3Z1pvU2xphywC6UK4GY5BgqSSUuaXbJmSsWLIAtW+CDD8DuxGWMKSfsDKIEViatpEvDLtSqWuvMFRMmODcFGmZTJRtjyg9LEF7KcmWxKmVVwf6HzExYudKZc6ly5eAEZ4wxfuDXBCEiA0XkVxGJF5GnPayvLSJfisg6EdkkIvfmWZcoIhtEZK2IBO4+ooVYv3c9JzJPFEwQycnO/abPPz84gRljjJ8UmyBE5EYRKXEiEZEQYBJwPdARGCEiHfMVGw1sVtWuQD/gXyJSJc/6q1S1W2H3Sw2knAn6ClxBnZDg/G3TJsARGWOMf3lz4B8ObBeR10TkwhJsOxKIV9UEVc0A5gKD85VRoKY4kxqFA4eArBLsI2BWJq+kea3mNK/d/MwVliCMMeVUsQlCVe8EugM7gBki8qOIjBSRmsVUbQok53md4l6W10TgQiAV2AA8qqqunF0Di0RktYiMLGwn7ljiRCRu//79xb2dUlFVYpJiPE/vnZAAVapAkyZ+2bcxxgSLV01HqnoU+ATnLKAxcCvwi4g8XEQ1T+M9Nd/rAcBaoAnQDZgoIjlDhPqoag+cJqrRInJlIbFNU9Veqtqrfn3/3E83KS2J3cd2e75ALiEBWraEkBC/7NsYY4LFmz6Im0RkPrAUqAxEqur1QFegqEmHUoC87THNcM4U8roX+FQd8cBOoAOAqqa6/+4D5uM0WQVFzgR9HmdwTUiw5iVjTLnkzRnE7cDrqtpFVce7D9io6kngT0XUiwXai0hrd8fzcOCLfGWSgP4AItIQuABIEJEaOU1YIlIDuA7YWIL35VMrk1ZSs0pNOjfoXHClJQhjTDnlzZXU/w/Yk/NCRMKAhqqaqKpLCqukqlkiMgaIBkKA6aq6SURGuddPBV4CZorIBpwmqadU9YCItAHmu2/IEwp8qKoLS/cWz17OBH0hlfI1Ix0+7DwsQRhjyiFvEsTHwGV5Xme7l/UurqKqLgAW5Fs2Nc/zVJyzg/z1EnCasIIuLT2NDXs3MKTvkIIrd+50/lqCMMaUQ940MYW6h6kC4H5epYjy5cqPKT+iaOH9D2AJwhhTLnmTIPaLyM05L0RkMHDAfyGVLTFJMYRICBc3u7jgypwE0bp1YIMyxpgA8KaJaRQwW0Qm4vQTJAN3+TWqMiQmOYaujboSXiW84MqEBDjvPKhdO/CBGWOMnxWbIFR1B3CJiIQDoqrH/B9W2ZCZnclPu3/ivu73eS5gI5iMMeWYV/eDEJEbgE5ANffIIlT1RT/GVSas/W0tJzNPer6CGpxO6p49AxuUMcYEiDcXyk0FhgEP4zQx3Q609HNcZULOBXIer6DOzobERDuDMMaUW950Ul+mqncBh1X1BeBSzrxCutyKSY6hZe2WNK2VfwopICUFsrIsQRhjyi1vEkS6++9JEWkCZALlftiOqrIyaaXn4a1gQ1yNMeWeN30QX4pIHWA88AvOhHvv+DWqMmDnkZ38dvw3z81LYAnCGFPuFZkg3DcKWqKqR4BPROQroJqqpgUkuiDKuUFQoR3UCQkQGgrNmgUwKmOMCZwim5jc92b4V57XpytCcgCn/6FW1Vp0qt/Jc4Gcab5DvRoIZowx5xxv+iAWichQyRnfWkGsTFrJZc0vKzhBXw67BsIYU855kyAex5mc77SIHBWRYyJy1M9xBdXhU4fZtH9T4f0P4CQIm2LDGFOOeXMldXG3Fi13fkz5ESjk+geAo0fhwAE7gzDGlGvFJogibvX5ve/DKRtikmIIrRRKZNNCbmJn03wbYyoAb3pYn8zzvBrOrT9XA1f7JaIyYGXySro36k6NKjU8F7AhrsaYCsCbJqab8r4WkebAa36LKMgysjP4effPjOo5qvBCliCMMRWAN53U+aUAF/k6kLJizZ41pGelF379AzgJok4dqFs3cIEZY0yAedMH8TbO1dPgJJRuwDpvNi4iA4E3ce5J/a6qjsu3vjYwC2jhjmWCqs7wpq6/rExaCRTRQQ02xNUYUyF40wcRl+d5FjBHVWOKqyQiIcAk4Fqcs45YEflCVTfnKTYa2KyqN4lIfeBXEZmNc9/r4ur6RUxyDG3qtqFxzcaFF0pIgC5d/B2KMcYElTcJ4n9Auqpmg3PgF5HqqnqymHqRQLyqJrjrzQUGA3kP8grUdF+EFw4cwklCF3tR1+dUlZjkGAa0HVB4oZxpvm+5xZ+hGGNM0HnTB7EECMvzOgxY7EW9pji3J82R4l6W10TgQiAV2AA86p7ew5u6AIjISBGJE5G4/fv3exFW4XYc3sG+E/sKn8EVIDUVMjKsickYU+55kyCqqerxnBfu59W9qOdpag7N93oAsBZogtO3MVFEanlZNyeeaaraS1V71a9f34uwCudV/4NdA2GMqSC8SRAnRKRHzgsR6Qmc8qJeCmfeWKgZzplCXvcCn6ojHtgJdPCyrs/FJMVQp1odLqx/YeGFbIirMaaC8KYPYizwsYjkHKAb49yCtDixQHsRaQ3sBoYD/5evTBLQH1ghIg2BC4AE4IgXdX0uJjmGy5pfRiUpIm8mJEClStCihb/DMcaYoPLmQrlYEemAc/AWYKuqZnpRL0tExgDROENVp6vqJhEZ5V4/FXgJmCkiG9zbfkpVDwB4qluqd+ilgycPsuXAFv7Y5Y9FF0xIcJJD5cr+DMcYY4LOm+sgRgOzVXWj+3VdERmhqpOLq6uqC4AF+ZZNzfM8FbjO27r+9EPyD0ARNwjKYddAGGMqCG/6IO5331EOAFU9DNzvv5CCIyY5hsqVKtO7Se+iC1qCMMZUEN4kiEp5bxbkvgCuiv9CCo6Y5Bh6NO5BWOWwwgudOAF791qCMMZUCN4kiGjgIxHpLyJXA3OAb/wbVmCdzjpN7O7Yoq9/gN+HuNqNgowxFYA3o5ieAkYCD+J0JK/BGclUbqzes5rT2aeLvv4BbIirMaZCKfYMwn1l8yqc4ae9cIalbvFzXAEVk+RMLXVZ88uKLmgJwhhTgRR6BiEi5+NcfzACOAjMA1DVqwITWuDEJMfQvl57GoY3LLpgQgLUrAnnnReYwIwxJoiKOoPYinO2cJOqXq6qb+PMslqu5EzQV+zwVvh9BJN4mgnEGGPKl6L6IIbinEEsE5GFwFw8z5F0Tst0ZfJUn6fo1qhb8YUTEqBDB/8HZYwxZUChCUJV5wPzRaQGcAvwGNBQRKYA81V1UYBi9KsqIVV44rInii/ocjmjmAYN8n9QxhhTBnjTSX1CVWer6o04k+atBZ72e2RlzW+/QXq6dVAbYyqMEt2TWlUPqep/VPVqfwVUZtkIJmNMBVOiBFGhWYIwxlQwliC8lZDgjF5q2TLYkRhjTEBYgvDWzp3QrBlUrRrsSIwxJiAsQXjLZnE1xlQwliC8ZQnCGFPBWILwxqlTkJpqCcIYU6FYgvBGYqLz1xKEMaYC8WuCEJGBIvKriMSLSIGL60TkSRFZ635sFJFsEannXpcoIhvc6+L8GWexbIirMaYC8uZ+EKXivvPcJOBaIAWIFZEvVHVzThlVHQ+Md5e/CXhMVQ/l2cxVqnrAXzF6zRKEMaYC8ucZRCQQr6oJqpqBM9nf4CLKj8C5W13Zk5AA1atD/frBjsQYYwLGnwmiKZCc53WKe1kBIlIdGAh8kmexAotEZLWIjCxsJyIyUkTiRCRu//79PgjbA5vm2xhTAfkzQXg6mmohZW8CYvI1L/VR1R7A9cBoEbnSU0VVnaaqvVS1V31//cK3Ia7GmArInwkiBWie53UzILWQssPJ17ykqqnuv/uA+ThNVoGnagnCGFMh+TNBxALtRaS1iFTBSQJf5C8kIrWBvsDneZbVEJGaOc+B64CNfoy1cPv2wcmTliCMMRWO30YxqWqWiIwBooEQYLqqbhKRUe71U91FbwUWqeqJPNUb4tysKCfGD1V1ob9iLZKNYDLGVFB+SxAAqroAWJBv2dR8r2cCM/MtSwC6+jM2r1mCMMZUUHYldXFyEkSrVkENwxhjAs0SRHESEqBJEwgLC3YkxhgTUJYgimMjmIwxFZQliOLs3GkJwhhTIVmCKMrp05CSYgnCGFMhWYIoyq5dzoVyliCMMRWQJYii2BBXY0wFZgmiKJYgjDEVmCWIoiQkQLVq0KhRsCMxxpiAswRRFJvm2xhTgVmCKEpCArRuHewojDEmKCxBFMam+TbGVHCWIApz8CAcO2YJwhhTYVmCKIyNYDLGVHCWIApjCcIYU8FZgihMToKwTmpjTAVlCaIwCQnQsCHUqBHsSIwxJij8miBEZKCI/Coi8SLytIf1T4rIWvdjo4hki0g9b+r6nY1gMsZUcH5LECISAkwCrgc6AiNEpGPeMqo6XlW7qWo34G/AclU95E1dv7MEYYyp4Px5BhEJxKtqgqpmAHOBwUWUHwHMKWVd38rIgORkSxDGmArNnwmiKZCc53WKe1kBIlIdGAh8UtK6fpGUBC6XJQhjTIXmzwThaQIjLaTsTUCMqh4qaV0RGSkicSISt3///lKE6cHOnc5fSxDGmArMnwkiBWie53UzILWQssP5vXmpRHVVdZqq9lLVXvXr1z+LcPOwayCMMcavCSIWaC8irUWkCk4S+CJ/IRGpDfQFPi9pXb9JSIAqVaBJk4Dt0hhjyppQf21YVbNEZAwQDYQA01V1k4iMcq+f6i56K7BIVU8UV9dfsRaQM4trJbtMxBhTcYlqYd0C555evXppXFzc2W+oZ0/nIrkFC85+W8YYU4aJyGpV7eVpnf1E9sSugTDGGEsQBRw+DEeO2BxMxpgKzxJEfjaCyRhjAD92Up+zLEGYciAzM5OUlBTS09ODHYopI6pVq0azZs2oXLmy13UsQeRn03ybciAlJYWaNWvSqlUrRDxdd2oqElXl4MGDpKSk0LoExzZrYsovIQEiIqBWrWBHYkyppaenc95551lyMACICOedd16JzygtQeRnI5hMOWHJweRVmu+DJYj8LEEYYwxgCeJMWVmwa5clCGPO0sGDB+nWrRvdunWjUaNGNG3aNPd1RkZGkXXj4uJ45JFHit3HZZdd5qtwAXj00Udp2rQpLpfLp9s9l1kndV7JyZCdbQnCmLN03nnnsXbtWgCioqIIDw/niSeeyF2flZVFaKjnw0+vXr3o1cvjhb1n+OGHH3wTLOByuZg/fz7Nmzfn+++/p1+/fj7bdl7Z2dmEhIT4Zdv+YAkiLxviasqjsWPBfbD2mW7d4I03SlTlnnvuoV69eqxZs4YePXowbNgwxo4dy6lTpwgLC2PGjBlccMEFfPfdd0yYMIGvvvqKqKgokpKSSEhIICkpibFjx+aeXYSHh3P8+HG+++47oqKiiIiIYOPGjfTs2ZNZs2YhIixYsIDHH3+ciIgIevToQUJCAl999VWB2JYtW8ZFF13EsGHDmDNnTm6C2Lt3L6NGjSLBfWyYMmUKl112Ge+//z4TJkxAROjSpQsffPAB99xzDzfeeCO33XZbgfheeOEFGjduzNq1a9m8eTO33HILycnJpKen8+ijjzJy5EgAFi5cyDPPPEN2djYRERF8++23XHDBBfzwww/Ur18fl8vF+eefz6pVq4iIiCjtv57XLEHkZQnCGL/atm0bixcvJiQkhKNHj/L9998TGhrK4sWLeeaZZ/jkk08K1Nm6dSvLli3j2LFjXHDBBTz44IMFxvKvWbOGTZs20aRJE/r06UNMTAy9evXigQce4Pvvv6d169aMGDGi0LjmzJnDiBEjGDx4MM888wyZmZlUrlyZRx55hL59+zJ//nyys7M5fvw4mzZt4uWXXyYmJoaIiAgOHTpU6HZz/Pzzz2zcuDF3iOn06dOpV68ep06donfv3gwdOhSXy8X999+fG++hQ4eoVKkSd955J7Nnz2bs2LEsXryYrl27BiQ5gCWIM+3cCaGh0KxZsCMxxndK+Evfn26//fbcJpa0tDTuvvtutm/fjoiQmZnpsc4NN9xA1apVqVq1Kg0aNGDv3r00y/d/NDIyMndZt27dSExMJDw8nDZt2uQelEeMGMG0adMKbD8jI4MFCxbw+uuvU7NmTS6++GIWLVrEDTfcwNKlS3n//fcBCAkJoXbt2rz//vvcdtttuQfpevXqFfu+IyMjz7j+4K233mL+/PkAJCcns337dvbv38+VV16ZWy5nu3/6058YPHgwY8eOZfr06dx7773F7s9XLEHklZAArVrBOdRGaMy5pEaNGrnPn3vuOa666irmz59PYmJioe3+VatWzX0eEhJCVlaWV2W8nal64cKFpKWl0blzZwBOnjxJ9erVueGGGzyWV1WPQ0ZDQ0NzO7hV9YzO+Lzv+7vvvmPx4sX8+OOPVK9enX79+pGenl7odps3b07Dhg1ZunQpP/30E7Nnz/bqffmCjWLKy4a4GhMwaWlpNG3q3Gp+5syZPt9+hw4dSEhIIDExEYB58+Z5LDdnzhzeffddEhMTSUxMZOfOnSxatIiTJ0/Sv39/pkyZAjgdzEePHqV///589NFHHDx4ECC3ialVq1asXr0agM8//7zQM6K0tDTq1q1L9erV2bp1K6tWrQLg0ksvZfny5ex03/I4b9PVfffdx5133skdd9wR0E5uSxB5WYIwJmD++te/8re//Y0+ffqQnZ3t8+2HhYUxefJkBg4cyOWXX07Dhg2pXbv2GWVOnjxJdHT0GWcLNWrU4PLLL+fLL7/kzTffZNmyZXTu3JmePXuyadMmOnXqxN///nf69u1L165defzxxwG4//77Wb58OZGRkfz0009nnDXkNXDgQLKysujSpQvPPfccl1xyCQD169dn2rRpDBkyhK5duzJs2LDcOjfffDPHjx8PaPMS2A2DfpeWBnXqwGuvwZNP+jYwYwJsy5YtXHjhhcEOI+iOHz9OeHg4qsro0aNp3749jz32WLDDKrG4uDgee+wxVqxYcVbb8fS9sBsGecN9WmdnEMaUH++88w7dunWjU6dOpKWl8cADDwQ7pBIbN24cQ4cO5ZVXXgn4vv16BiEiA4E3ce4r/a6qjvNQph/wBlAZOKCqfd3LE4FjQDaQVViGy+usziA+/RSGDoXVq6FHj9Jtw5gyws4gjCclPYPw2ygmEQkBJgHXAilArIh8oaqb85SpA0wGBqpqkog0yLeZq1T1gL9iPINdA2GMMWfwZxNTJBCvqgmqmgHMBQbnK/N/wKeqmgSgqvv8GE/REhKgbl2nH8IYY4xfE0RTIDnP6xT3srzOB+qKyHcislpE7sqzToFF7uUjC9uJiIwUkTgRidu/f3/po7URTMYYcwZ/XijnafLx/B0eoUBPoD8QBvwoIqtUdRvQR1VT3c1O34rIVlX9vsAGVacB08Dpgyh1tAkJzvwyxhhjAP+eQaQAzfO8bgakeiizUFVPuPsavge6AqhqqvvvPmA+TpOVf2RnQ2KinUEY4yP9+vUjOjr6jGVvvPEGDz30UJF1cgaZDBo0iCNHjhQoExUVxYQJE4rc92effcbmzbldnTz//PMsXry4JOEXqSJNC+7PBBELtBeR1iJSBRgOfJGvzOfAFSISKiLVgYuBLSJSQ0RqAohIDeA6YKPfIt29GzIzLUEY4yMjRoxg7ty5ZyybO3dukRPm5bVgwQLqlLI/MH+CePHFF7nmmmtKta388k8L7i/+uHCwNPzWxKSqWSIyBojGGeY6XVU3icgo9/qpqrpFRBYC6wEXzlDYjSLSBpjvnpckFPhQVRf6K1YbwWTKs7ELx7L2N99O992tUTfeGFj4JIC33XYbzz77LKdPn6Zq1aokJiaSmprK5ZdfzoMPPkhsbCynTp3itttu44UXXihQv1WrVsTFxREREcHLL7/M+++/T/Pmzalfvz49e/YEnGscpk2bRkZGBu3ateODDz5g7dq1fPHFFyxfvpx//OMffPLJJ7z00ku503AvWbKEJ554gqysLHr37s2UKVOoWrUqrVq14u677+bLL78kMzOTjz/+mA4dOhSIq6JNC+7XyfpUdQGwIN+yqflejwfG51uWgLupKSAsQRjjU+eddx6RkZEsXLiQwYMHM3fuXIYNG4aI8PLLL1OvXj2ys7Pp378/69evp0uXLh63s3r1aubOncuaNWvIysqiR48euQliyJAh3H///QA8++yzvPfeezz88MPcfPPNZxyAc6Snp3PPPfewZMkSzj//fO666y6mTJnC2LFjAYiIiOCXX35h8uTJTJgwgXfffbdAPBVtWnCbzRWcBBESAs2bF1/WmHNMUb/0/SmnmSknQUyfPh2Ajz76iGnTppGVlcWePXvYvHlzoQlixYoV3HrrrVSvXh1w5iTKsXHjRp599lmOHDnC8ePHGTBgQJHx/Prrr7Ru3Zrzzz8fgLvvvptJkyblJoghQ4YA0LNnTz799NMC9SvitOCWIMBJEC1aQL6bkBhjSu+WW27h8ccf55dffuHUqVP06NGDnTt3MmHCBGJjY6lbty733HMP6enpRW7H0xTY4Nyh7rPPPqNr167MnDmT7777rsjtFDdrRM6U4YVNKV4RpwW3uZjAroEwxg/Cw8Pp168ff/rTn3I7p48ePUqNGjWoXbs2e/fu5ZtvvilyG1deeSXz58/n1KlTHDt2jC+//DJ33bFjx2jcuDGZmZlnHAxr1qzJsWPHCmyrQ4cOJCYmEh8fD8AHH3xA3759vX4/FXFacEsQ4EzUZwnCGJ8bMWIE69atY/jw4QB07dqV7t2706lTJ/70pz/Rp0+fIuvn3Lu6W7duDB06lCuuuCJ33UsvvcTFF1/Mtddee0aH8vDhwxk/fjzdu3dnx44ducurVavGjBkzuP322+ncuTOVKlVi1KhRXr2PijotuE33nZ0N994L110Hd97pn8CMCTCbrK9iKm5a8DIzWd85IyQE3J1Lxhhzrho3bhxTpkzx6S1JrYnJGGPKgaeffppdu3Zx+eWX+2ybliCMKafKU/OxOXul+T5YgjCmHKpWrRoHDx60JGEAJzkcPHiQatWqlaie9UEYUw41a9aMlJQUzmoKfFOuVKtWjWbNmpWojiUIY8qhypUrn3FFrjGlYU1MxhhjPLIEYYwxxiNLEMYYYzwqV1dSi8h+YFew4yhEBHAg2EEUweI7Oxbf2bH4zs7ZxNdSVet7WlGuEkRZJiJxhV3OXhZYfGfH4js7Ft/Z8Vd81sRkjDHGI0sQxhhjPLIEETjTgh1AMSy+s2PxnR2L7+z4JT7rgzDGGOORnUEYY4zxyBKEMcYYjyxB+JCINBeRZSKyRUQ2icijHsr0E5E0EVnrfjwf4BgTRWSDe98Fbr8njrdEJF5E1otIjwDGdkGez2WtiBwVkbH5ygT08xOR6SKyT0Q25llWT0S+FZHt7r91C6k7UER+dX+WTwcwvvEistX97zdfROoUUrfI74If44sSkd15/g0HFVI3WJ/fvDyxJYrI2kLqBuLz83hMCdh3UFXt4aMH0Bjo4X5eE9gGdMxXph/wVRBjTAQiilg/CPgGEOAS4KcgxRkC/IZzEU/QPj/gSqAHsDHPsteAp93PnwZeLST+HUAboAqwLv93wY/xXQeEup+/6ik+b74LfowvCnjCi3//oHx++db/C3g+iJ+fx2NKoL6DdgbhQ6q6R1V/cT8/BmwBmgY3qhIbDLyvjlVAHRFpHIQ4+gM7VDWoV8ar6vfAoXyLBwP/dT//L3CLh6qRQLyqJqhqBjDXXc/v8anqIlXNcr9cBZRsjmcfKuTz80bQPr8cIiLAHcAcX+/XW0UcUwLyHbQE4Sci0groDvzkYfWlIrJORL4RkU4BDQwUWCQiq0VkpIf1TYHkPK9TCE6SG07h/zGD+fkBNFTVPeD8BwYaeChTVj7HP+GcEXpS3HfBn8a4m8CmF9I8UhY+vyuAvaq6vZD1Af388h1TAvIdtAThByISDnwCjFXVo/lW/4LTbNIVeBv4LMDh9VHVHsD1wGgRuTLfevFQJ6BjoUWkCnAz8LGH1cH+/LxVFj7HvwNZQGF3sS/uu+AvU4C2QDdgD04zTn5B//yAERR99hCwz6+YY0qh1TwsK9FnaAnCx0SkMs4/5GxV/TT/elU9qqrH3c8XAJVFJCJQ8alqqvvvPmA+zmloXilA8zyvmwGpgYku1/XAL6q6N/+KYH9+bntzmt3cf/d5KBPUz1FE7gZuBP6g7gbp/Lz4LviFqu5V1WxVdQHvFLLfYH9+ocAQYF5hZQL1+RVyTAnId9AShA+52yzfA7ao6r8LKdPIXQ4RicT5NzgYoPhqiEjNnOc4nZkb8xX7ArjLPZrpEiAt51Q2gAr95RbMzy+PL4C73c/vBj73UCYWaC8ird1nRMPd9fxORAYCTwE3q+rJQsp4813wV3x5+7RuLWS/Qfv83K4BtqpqiqeVgfr8ijimBOY76M8e+Ir2AC7HOYVbD6x1PwYBo4BR7jJjgE04IwpWAZcFML427v2uc8fwd/fyvPEJMAln9MMGoFeAP8PqOAf82nmWBe3zw0lUe4BMnF9kfwbOA5YA291/67nLNgEW5Kk7CGfUyY6czzpA8cXjtD3nfAen5o+vsO9CgOL7wP3dWo9zwGpclj4/9/KZOd+5PGWD8fkVdkwJyHfQptowxhjjkTUxGWOM8cgShDHGGI8sQRhjjPHIEoQxxhiPLEEYY4zxyBKEMcUQkWw5c5ZZn80sKiKt8s4kakxZEhrsAIw5B5xS1W7BDsKYQLMzCGNKyX0/gFdF5Gf3Pd16wQAAAalJREFUo517eUsRWeKejG6JiLRwL28ozv0Z1rkfl7k3FSIi77jn+18kImHu8o+IyGb3duYG6W2aCswShDHFC8vXxDQsz7qjqhoJTATecC+biDNlehecifLeci9/C1iuzkSDPXCuwAVoD0xS1U7AEWCoe/nTQHf3dkb5680ZUxi7ktqYYojIcVUN97A8EbhaVRPcE6r9pqrnicgBnOkjMt3L96hqhIjsB5qp6uk822gFfKuq7d2vnwIqq+o/RGQhcBxnxtrP1D1JoTGBYmcQxpwdLeR5YWU8OZ3neTa/9w3egDMvVk9gtXuGUWMCxhKEMWdnWJ6/P7qf/4AzcybAH4CV7udLgAcBRCRERGoVtlERqQQ0V9VlwF+BOkCBsxhj/Ml+kRhTvDA588b1C1U1Z6hrVRH5CefH1gj3skeA6SLyJLAfuNe9/FFgmoj8GedM4UGcmUQ9CQFmiUhtnBl2X1fVIz57R8Z4wfogjCkldx9EL1U9EOxYjPEHa2IyxhjjkZ1BGGOM8cjOIIwxxnhkCcIYY4xHliCMMcZ4ZAnCGGOMR5YgjDHGePT/AWAJOkMzlqJcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, color='red', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, color='green', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the F1 Score\n",
    "\n",
    "### Getting the actual targets and the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('brain_vgg16_final.h5')\n",
    "preds = classifier.predict(X_test)\n",
    "actual = []\n",
    "predictions = []\n",
    "for i in range(len(preds)):\n",
    "    actual.append(np.argmax(Y_test[i]))\n",
    "    predictions.append(np.argmax(preds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data for evaluation of precision, recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,b1,c1,d1,a2,b2,c2,d2,a3,b3,c3,d3,a4,b4,c4,d4 = 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "for j in range(len(actual)):\n",
    "    if actual[j] == 0:\n",
    "        if predictions[j] == 0:\n",
    "            a1 += 1\n",
    "        elif predictions[j] == 1:\n",
    "            a2 += 1\n",
    "        elif predictions[j] == 2:\n",
    "            a3 += 1\n",
    "        else:\n",
    "            a4 += 1\n",
    "    elif actual[j] == 1:\n",
    "        if predictions[j] == 0:\n",
    "            b1 += 1\n",
    "        elif predictions[j] == 1:\n",
    "            b2 += 1\n",
    "        elif predictions[j] == 2:\n",
    "            b3 += 1\n",
    "        else:\n",
    "            b4 += 1\n",
    "    elif actual[j] == 2:\n",
    "        if predictions[j] == 0:\n",
    "            c1 += 1\n",
    "        elif predictions[j] == 1:\n",
    "            c2 += 1\n",
    "        elif predictions[j] == 2:\n",
    "            c3 += 1\n",
    "        else:\n",
    "            c4 += 1\n",
    "    elif actual[j] == 3:\n",
    "        if predictions[j] == 0:\n",
    "            d1 += 1\n",
    "        elif predictions[j] == 1:\n",
    "            d2 += 1\n",
    "        elif predictions[j] == 2:\n",
    "            d3 += 1\n",
    "        else:\n",
    "            d4 += 1\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_mean(x,y):\n",
    "    return (2*(x*y)/(x+y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding recall, precision and F1 score for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score for flair class is : 0.9734513274336283\n",
      "The F1 score for t1 class is : 0.9661016949152542\n",
      "The F1 score for t1ce class is : 0.9586776859504132\n",
      "The F1 score for t2 class is : 1.0\n",
      "\n",
      "Average F1 score is:  0.9745576770748239\n"
     ]
    }
   ],
   "source": [
    "#flair\n",
    "tpf = a1\n",
    "fpf = b1+c1+d1\n",
    "fnf = a2+a3+a4\n",
    "precision_flair = tpf/(tpf + fpf)\n",
    "recall_flair = tpf/(tpf+fnf)\n",
    "try:\n",
    "    F1_flair = h_mean(precision_flair, recall_flair)\n",
    "    print('The F1 score for flair class is :', F1_flair)\n",
    "except:\n",
    "    print('Sorry division by zero')\n",
    "\n",
    "#t1\n",
    "tpt1 = b2\n",
    "fpt1 = a2+c2+d2\n",
    "fnt1 = b1+b3+b4\n",
    "precision_t1 = tpt1/(tpt1 + fpt1)\n",
    "recall_t1 = tpt1/(tpt1+fnt1)\n",
    "try:\n",
    "    F1_t1 = h_mean(precision_t1, recall_t1)\n",
    "    print('The F1 score for t1 class is :', F1_t1)\n",
    "except:\n",
    "    print('Sorry division by zero')\n",
    "\n",
    "#t1ce\n",
    "tpt1ce = c3\n",
    "fpt1ce = a3+b3+d3\n",
    "fnt1ce = c1+c2+c4\n",
    "try:\n",
    "    precision_t1ce = tpt1ce/(tpt1ce + fpt1ce)\n",
    "    recall_t1ce = tpt1ce/(tpt1ce+fnt1ce)\n",
    "    F1_t1ce = h_mean(precision_t1ce, recall_t1ce)\n",
    "    print('The F1 score for t1ce class is :', F1_t1ce)\n",
    "except:\n",
    "    print('Sorry division by zero, therefore = 0')\n",
    "    \n",
    "    \n",
    "#t2\n",
    "tpt2 = d4\n",
    "fpt2 = a4+b4+c4\n",
    "fnt2 = d1+d2+d3\n",
    "try:\n",
    "    precision_t2 = tpt2/(tpt2 + fpt2)\n",
    "    recall_t2 = tpt2/(tpt2+fnt2)\n",
    "    F1_t2 = h_mean(precision_t2, recall_t2)\n",
    "    print('The F1 score for t2 class is :', F1_t2)\n",
    "except:\n",
    "    print('Sorry division by zero')\n",
    "    \n",
    "    \n",
    "    \n",
    "print('\\nAverage F1 score is: ', (F1_flair+F1_t1+F1_t1ce+F1_t2)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>t1</th>\n",
       "      <th>t1ce</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flair</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1ce</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       flair  t1  t1ce  t2\n",
       "flair     55   1     2   0\n",
       "t1         0  57     3   0\n",
       "t1ce       0   0    58   0\n",
       "t2         0   0     0  65"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [[a1,b1,c1,d1], [a2,b2,c2,d2], [a3,b3,c3,d3], [a4,b4,c4,d4]]\n",
    "table = np.array(table)\n",
    "confusion_matrix = pd.DataFrame(data = table, index = ['flair', 't1', 't1ce', 't2'], columns = ['flair', 't1', 't1ce', 't2'] )\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def build_classifier():\n",
    "    x = Conv2D(200, (1,1), activation = 'relu', input_shape = last.shape[1:])(last)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation = 'relu')(x)\n",
    "    x = Dropout(rate = 0.25)(x)\n",
    "    x = Dense(256, activation = 'relu')(x)\n",
    "    x = Dropout(rate = 0.25)(x)\n",
    "    x = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "    classifier = Model(inputs = model.input, outputs = x)\n",
    "    opt1 = Adam(learning_rate = 0.001)\n",
    "    opt2 = RMSprop(learning_rate = 0.001)\n",
    "    classifier.compile(optimizer = opt2 , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples\n",
      "Epoch 1/15\n",
      "600/600 [==============================] - 22s 36ms/sample - loss: 2.3609 - accuracy: 0.5367\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 21s 35ms/sample - loss: 0.4496 - accuracy: 0.8233\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 21s 35ms/sample - loss: 0.2661 - accuracy: 0.8983\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 21s 35ms/sample - loss: 0.1762 - accuracy: 0.9433\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 21s 35ms/sample - loss: 0.1437 - accuracy: 0.9650\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 21s 35ms/sample - loss: 0.1112 - accuracy: 0.9683\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 21s 35ms/sample - loss: 0.0483 - accuracy: 0.9867\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 21s 36ms/sample - loss: 0.0554 - accuracy: 0.9833\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 22s 36ms/sample - loss: 0.0354 - accuracy: 0.9900\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 22s 36ms/sample - loss: 3.1792e-04 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 22s 36ms/sample - loss: 0.0547 - accuracy: 0.9883\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 23s 38ms/sample - loss: 0.0465 - accuracy: 0.9850\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 22s 37ms/sample - loss: 8.6874e-05 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 22s 37ms/sample - loss: 0.0205 - accuracy: 0.9950\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 22s 37ms/sample - loss: 7.0628e-05 - accuracy: 1.0000\n",
      "121/121 [==============================] - 5s 38ms/sample - loss: 0.9626 - accuracy: 0.9091\n",
      "Train on 601 samples\n",
      "Epoch 1/15\n",
      "601/601 [==============================] - 23s 39ms/sample - loss: 2.4943 - accuracy: 0.5291\n",
      "Epoch 2/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.4215 - accuracy: 0.8469\n",
      "Epoch 3/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.2518 - accuracy: 0.9101\n",
      "Epoch 4/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.1264 - accuracy: 0.9567\n",
      "Epoch 5/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.1470 - accuracy: 0.9468\n",
      "Epoch 6/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.1024 - accuracy: 0.9717\n",
      "Epoch 7/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.0475 - accuracy: 0.9834\n",
      "Epoch 8/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0955 - accuracy: 0.9867\n",
      "Epoch 9/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0857 - accuracy: 0.9867\n",
      "Epoch 10/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 6.0268e-04 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0522 - accuracy: 0.9950\n",
      "Epoch 12/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 2.4337e-05 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0488 - accuracy: 0.9917\n",
      "Epoch 14/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1061 - accuracy: 0.9900\n",
      "Epoch 15/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0456 - accuracy: 0.9900\n",
      "120/120 [==============================] - 5s 38ms/sample - loss: 0.4911 - accuracy: 0.8833\n",
      "Train on 601 samples\n",
      "Epoch 1/15\n",
      "601/601 [==============================] - 23s 38ms/sample - loss: 2.1931 - accuracy: 0.5291\n",
      "Epoch 2/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.4264 - accuracy: 0.8552\n",
      "Epoch 3/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.2535 - accuracy: 0.9168\n",
      "Epoch 4/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1615 - accuracy: 0.9451\n",
      "Epoch 5/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0984 - accuracy: 0.9651\n",
      "Epoch 6/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0524 - accuracy: 0.9834\n",
      "Epoch 7/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0579 - accuracy: 0.9834\n",
      "Epoch 8/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0655 - accuracy: 0.9884\n",
      "Epoch 9/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0906 - accuracy: 0.9850\n",
      "Epoch 10/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0261 - accuracy: 0.9933\n",
      "Epoch 11/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0581 - accuracy: 0.9867\n",
      "Epoch 12/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 7.0803e-05 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0357 - accuracy: 0.9917\n",
      "Epoch 14/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 4.0525e-05 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0262 - accuracy: 0.9917\n",
      "120/120 [==============================] - 4s 37ms/sample - loss: 0.5319 - accuracy: 0.9417\n",
      "Train on 601 samples\n",
      "Epoch 1/15\n",
      "601/601 [==============================] - 23s 38ms/sample - loss: 2.4360 - accuracy: 0.5341\n",
      "Epoch 2/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.4329 - accuracy: 0.8502\n",
      "Epoch 3/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.2547 - accuracy: 0.9201\n",
      "Epoch 4/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1533 - accuracy: 0.9517\n",
      "Epoch 5/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1426 - accuracy: 0.9468\n",
      "Epoch 6/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0453 - accuracy: 0.9884\n",
      "Epoch 7/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.0800 - accuracy: 0.9817\n",
      "Epoch 8/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0521 - accuracy: 0.9950\n",
      "Epoch 9/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0625 - accuracy: 0.9867\n",
      "Epoch 10/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0781 - accuracy: 0.9800\n",
      "Epoch 11/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0334 - accuracy: 0.9950\n",
      "Epoch 12/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.0808 - accuracy: 0.9850\n",
      "Epoch 13/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 9.8614e-05 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0898 - accuracy: 0.9933\n",
      "Epoch 15/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0988 - accuracy: 0.9884\n",
      "120/120 [==============================] - 4s 37ms/sample - loss: 0.2745 - accuracy: 0.9500\n",
      "Train on 601 samples\n",
      "Epoch 1/15\n",
      "601/601 [==============================] - 23s 38ms/sample - loss: 2.1628 - accuracy: 0.5607\n",
      "Epoch 2/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.4021 - accuracy: 0.8636\n",
      "Epoch 3/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.2561 - accuracy: 0.9218\n",
      "Epoch 4/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1191 - accuracy: 0.9601\n",
      "Epoch 5/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1256 - accuracy: 0.9667\n",
      "Epoch 6/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1298 - accuracy: 0.9717\n",
      "Epoch 7/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0570 - accuracy: 0.9867\n",
      "Epoch 8/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0841 - accuracy: 0.9867\n",
      "Epoch 9/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0368 - accuracy: 0.9884\n",
      "Epoch 10/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0132 - accuracy: 0.9983\n",
      "Epoch 11/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1255 - accuracy: 0.9800\n",
      "Epoch 12/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0248 - accuracy: 0.9917\n",
      "Epoch 13/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0248 - accuracy: 0.9983\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0340 - accuracy: 0.9967\n",
      "Epoch 15/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0248 - accuracy: 0.9967\n",
      "120/120 [==============================] - 4s 37ms/sample - loss: 0.4979 - accuracy: 0.9583\n",
      "Train on 601 samples\n",
      "Epoch 1/15\n",
      "601/601 [==============================] - 23s 39ms/sample - loss: 2.5387 - accuracy: 0.4925\n",
      "Epoch 2/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.4206 - accuracy: 0.8369\n",
      "Epoch 3/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.2462 - accuracy: 0.9285\n",
      "Epoch 4/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.1842 - accuracy: 0.9434\n",
      "Epoch 5/15\n",
      "601/601 [==============================] - 23s 38ms/sample - loss: 0.0820 - accuracy: 0.9700\n",
      "Epoch 6/15\n",
      "601/601 [==============================] - 24s 40ms/sample - loss: 0.0583 - accuracy: 0.9734\n",
      "Epoch 7/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.0849 - accuracy: 0.9834\n",
      "Epoch 8/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.0533 - accuracy: 0.9867\n",
      "Epoch 9/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0495 - accuracy: 0.9867\n",
      "Epoch 10/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0383 - accuracy: 0.9917\n",
      "Epoch 11/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.0830 - accuracy: 0.9817\n",
      "Epoch 12/15\n",
      "601/601 [==============================] - 22s 37ms/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0142 - accuracy: 0.9933\n",
      "Epoch 14/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 15/15\n",
      "601/601 [==============================] - 22s 36ms/sample - loss: 0.0784 - accuracy: 0.9834\n",
      "120/120 [==============================] - 4s 37ms/sample - loss: 1.1956 - accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = Y_train, cv = 6)\n",
    "\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AVERAGE accuracy after the cross validation is :  0.9292929271856943\n",
      "The VARIANCE of the accuracy after the cross validation is :  0.025696841856770312\n",
      "\n",
      "The accuracies for the cross validation are :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy\n",
       "1  0.909091\n",
       "2  0.883333\n",
       "3  0.941667\n",
       "4  0.950000\n",
       "5  0.958333\n",
       "6  0.933333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = pd.DataFrame(data = accuracies, index = list(range(1,7)), columns = ['Accuracy'])\n",
    "print('The AVERAGE accuracy after the cross validation is : ', mean)\n",
    "print('The VARIANCE of the accuracy after the cross validation is : ', variance)\n",
    "print('\\nThe accuracies for the cross validation are :\\n')\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
